{
    "features": "Возможности",
    "faq": "Вопросы",
    "download": "Скачать",
    "hero.title1": "Ваш локальные",
    "hero.title2": "AI инструменты.",
    "hero.subtitle": "Запускайте Llama, DeepSeek, Qwen, Gemma локально на своем компьютере.",
    "hero.download": "⬇️ Скачать Fllama",
    "spotlight.title": "Локальный AI Клиент",
    "spotlight.desc": "Fllama объединяет мощь локальных LLM с красивым и интуитивным интерфейсом. Наслаждайтесь приватностью, скоростью и полным контролем.",
    "spotlight.feature1.title": "Поддержка множества моделей",
    "spotlight.feature1.desc": "Запускайте Llama, Mistral, Gemma, Qwen и другие — все локально.",
    "spotlight.feature2.title": "Молниеносная скорость",
    "spotlight.feature2.desc": "Мгновенный запуск, легковесность, отсутствие лишнего. Оптимизировано для скорости.",
    "spotlight.feature3.title": "Полная приватность",
    "spotlight.feature3.desc": "Все данные остаются на вашем устройстве. Никаких облаков и отслеживания.",
    "highlights.1": "Открытый код",
    "highlights.2": "Быстрые обновления",
    "highlights.3": "Нативное приложение",
    "features.title": "Возможности",
    "features.1.title": "Кроссплатформенность",
    "features.1.desc": "Работает на Windows, macOS (Intel и Apple Silicon) и Linux.",
    "features.2.title": "Быстрый и легковесный",
    "features.2.desc": "Мгновенный запуск, минимальное использование ресурсов, отсутствие лишнего.",
    "features.3.title": "Интеграция с Ollama",
    "features.3.desc": "Общайтесь с любыми моделями Ollama локально, включая Llama 3, Mistral, Gemma, Qwen и другие.",
    "faq.title": "Часто задаваемые вопросы",
    "faq.1.question": "Собирает ли Fllama какие-либо данные?",
    "faq.1.answer": "Нет. Все ваши данные остаются на вашем компьютере. Fllama не собирает и не отправляет никакие данные.",
    "faq.2.question": "Могу ли я использовать Fllama в компании или организации?",
    "faq.2.answer": "Да! Fllama бесплатна для внутреннего использования в бизнесе и личных целях. Подробности см. в лицензии.",
    "faq.3.question": "Какие минимальные требования?",
    "faq.3.answer": "Требуется Ollama. Fllama работает на Windows, macOS (Intel/Apple Silicon) и Linux.",
    "faq.4.question": "Какие модели я могу запускать?",
    "faq.4.answer": "Любые модели, поддерживаемые Ollama, включая Llama, Mistral, Gemma, Qwen и другие. См. <a href=\"https://ollama.com/library\" target=\"_blank\">Библиотеку моделей Ollama</a>.",
    "faq.5.question": "Является ли Fllama открытым ПО?",
    "faq.5.answer": "Да! Код доступен на <a href=\"https://github.com/arduradiokot/fllama\" target=\"_blank\">GitHub</a> под лицензией GPL v2.0.",
    "download.title": "Скачать Fllama",
    "download.subtitle": "Выберите версию для вашей операционной системы и начните работать с локальными AI моделями уже сегодня.",
    "download.windows.title": "Windows",
    "download.windows.desc": "Полная поддержка Windows 10 и 11. Простая установка и автоматические обновления.",
    "download.macos.title": "macOS",
    "download.macos.desc": "Нативная поддержка macOS 11+ с оптимизацией для Apple Silicon и Intel процессоров.",
    "download.linux.title": "Linux",
    "download.linux.desc": "Работает на всех основных дистрибутивах Linux. Простая установка через CLI.",
    "download.version": "Версия 1.0.0",
    "download.button": "Скачать",
    "getstarted.title": "Начните работу с Fllama",
    "getstarted.button": "Скачать для вашей ОС",
    "getstarted.note": "Fllama бесплатна для домашнего и рабочего использования &bull; <a href=\"LICENSE\" target=\"_blank\">условия</a>",
    "getstarted.terms": "условия",
    "footer.copyright": "2025 Fllama",
    "footer.github": "GitHub",
    "footer.license": "Лицензия: GPL v2.0"
}