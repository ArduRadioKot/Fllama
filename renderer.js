const chat = document.getElementById('chat');
const form = document.getElementById('chat-form');
const input = document.getElementById('user-input');
const modelSelect = document.getElementById('model-select');

let markdownHighlightEnabled = true;
let currentStreamHandler = null;
let chatFontSize = 16;

// –°–∏—Å—Ç–µ–º–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —á–∞—Ç–∞–º–∏
let chats = [];
let currentChatIndex = 0;

function createNewChat() {
  const newChat = {
    id: Date.now(),
    name: `–ß–∞—Ç ${chats.length + 1}`,
    messages: []
  };
  chats.push(newChat);
  currentChatIndex = chats.length - 1;
  updateChatDisplay();
  saveChats();
}

function switchToChat(index) {
  if (index >= 0 && index < chats.length) {
    currentChatIndex = index;
    updateChatDisplay();
  }
}

function updateChatDisplay() {
  // –û—á–∏—â–∞–µ–º —á–∞—Ç
  chat.innerHTML = '';
  
  if (chats.length === 0) {
    createNewChat();
    return;
  }
  
  const currentChat = chats[currentChatIndex];
  
  // –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ —á–∞—Ç–∞
  currentChat.messages.forEach(msg => {
    const div = document.createElement('div');
    div.className = 'message ' + msg.sender;
    div.style.fontSize = chatFontSize + 'px';
    
    if (msg.sender === 'ai' && msg.isMarkdown && markdownHighlightEnabled) {
      // –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º AI —Å–æ–æ–±—â–µ–Ω–∏—è —Å —Ç–µ–≥–∞–º–∏ <think>
      const thinkMatch = msg.text.match(/<think>([\s\S]*?)<\/think>/i);
      if (thinkMatch) {
        const think = thinkMatch[1].trim();
        const answer = msg.text.replace(thinkMatch[0], '').trim();
        div.innerHTML = formatThinkingAndAnswer(think, answer);
        addCopyButtonsToCodeBlocks(div);
      } else {
        div.innerHTML = simpleMarkdown(msg.text);
        addCopyButtonsToCodeBlocks(div);
      }
    } else if (msg.isMarkdown && markdownHighlightEnabled) {
      div.innerHTML = simpleMarkdown(msg.text);
      addCopyButtonsToCodeBlocks(div);
    } else if (msg.isMarkdown) {
      div.innerHTML = escapeHtml(msg.text).replace(/\n/g, '<br>');
    } else {
      div.textContent = msg.text;
    }
    
    chat.appendChild(div);
  });
  
  chat.scrollTop = chat.scrollHeight;
  
  // –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –≤–∫–ª–∞–¥–æ–∫
  updateTabsList();
}

function updateTabsList() {
  const tabsList = document.getElementById('tabs-list');
  tabsList.innerHTML = '';
  
  chats.forEach((chat, index) => {
    const tabItem = document.createElement('div');
    tabItem.className = `tab-item ${index === currentChatIndex ? 'active' : ''}`;
    tabItem.innerHTML = `
      <span class="tab-name">${chat.name}</span>
      <button class="tab-close" title="–ó–∞–∫—Ä—ã—Ç—å —á–∞—Ç" data-tab-index="${index}">‚úñ</button>
    `;
    
    tabItem.addEventListener('click', (e) => {
      if (!e.target.classList.contains('tab-close')) {
        switchToChat(index);
      }
    });
    
    const closeBtn = tabItem.querySelector('.tab-close');
    closeBtn.addEventListener('click', (e) => {
      e.stopPropagation();
      deleteChat(index);
    });
    
    tabsList.appendChild(tabItem);
  });
}

function deleteChat(index) {
  if (chats.length <= 1) {
    alert('–ù–µ–ª—å–∑—è —É–¥–∞–ª–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞—Ç');
    return;
  }
  
  chats.splice(index, 1);
  
  if (currentChatIndex >= chats.length) {
    currentChatIndex = chats.length - 1;
  } else if (currentChatIndex > index) {
    currentChatIndex--;
  }
  
  updateChatDisplay();
  saveChats();
}

function saveChats() {
  localStorage.setItem('ollama-chats', JSON.stringify(chats));
  localStorage.setItem('ollama-current-chat', currentChatIndex);
}

function loadChats() {
  const savedChats = localStorage.getItem('ollama-chats');
  const savedCurrentChat = localStorage.getItem('ollama-current-chat');
  
  if (savedChats) {
    chats = JSON.parse(savedChats);
    currentChatIndex = parseInt(savedCurrentChat) || 0;
  } else {
    createNewChat();
  }
  
  updateChatDisplay();
}

// –ì–ª–æ–±–∞–ª—å–Ω—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞
function setupStreamHandler() {
  currentStreamHandler = (event, data) => {
    if (!window.currentAiMessageDiv || window.stopped) return;
    
    window.fullMessage += data.content;
    
   
    const thinkMatch = window.fullMessage.match(/<think>([\s\S]*?)<\/think>/i);
    if (thinkMatch) {
      window.think = thinkMatch[1].trim();
      window.answer = window.fullMessage.replace(thinkMatch[0], '').trim();
    } else {
      window.answer = window.fullMessage;
    }
    

    if (markdownHighlightEnabled) {
      window.currentAiMessageDiv.innerHTML = formatThinkingAndAnswer(window.think, window.answer);
      addCopyButtonsToCodeBlocks(window.currentAiMessageDiv);
    } else {
      let displayText = '';
      if (window.think) {
        displayText += '**–ú—ã—Å–ª–∏:**\n' + window.think + '\n\n';
      }
      displayText += window.answer;
      window.currentAiMessageDiv.textContent = displayText;
    }
    
    chat.scrollTop = chat.scrollHeight;
  };
  
  window.electronAPI.onStreamUpdate(currentStreamHandler);
}

// --- Markdown –ø–∞—Ä—Å–µ—Ä –±–µ–∑ —Å—Ç–æ—Ä–æ–Ω–Ω–∏—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ ---
function simpleMarkdown(text) {
  // –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º HTML
  text = escapeHtml(text);
  // –ë–ª–æ–∫–∏ –∫–æ–¥–∞ ```
  text = text.replace(/```([\s\S]*?)```/g, (m, code) => `\n<div class=\"md-code-outer\"><pre class=\"md-code-block\"><code>${code.trim()}</code></pre></div>\n`);
  // –ò–Ω–ª–∞–π–Ω-–∫–æ–¥
  text = text.replace(/`([^`]+)`/g, (m, code) => `<code class=\"md-inline-code\">${code}</code>`);
  // –ó–∞–≥–æ–ª–æ–≤–∫–∏ #
  text = text.replace(/^###### (.*)$/gm, '<h6>$1</h6>')
             .replace(/^##### (.*)$/gm, '<h5>$1</h5>')
             .replace(/^#### (.*)$/gm, '<h4>$1</h4>')
             .replace(/^### (.*)$/gm, '<h3>$1</h3>')
             .replace(/^## (.*)$/gm, '<h2>$1</h2>')
             .replace(/^# (.*)$/gm, '<h1>$1</h1>');
  // –ñ–∏—Ä–Ω—ã–π ** ** –∏ __ __
  text = text.replace(/\*\*(.*?)\*\*/g, '<b>$1</b>')
             .replace(/__(.*?)__/g, '<b>$1</b>');
  // –ö—É—Ä—Å–∏–≤ * * –∏ _ _
  text = text.replace(/\*(.*?)\*/g, '<i>$1</i>')
             .replace(/_(.*?)_/g, '<i>$1</i>');
  // –°—Å—ã–ª–∫–∏ [—Ç–µ–∫—Å—Ç](url)
  text = text.replace(/\[([^\]]+)\]\(([^\)]+)\)/g, '<a href="$2" target="_blank">$1</a>');
  // –ú–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
  text = text.replace(/(^|\n)[\*\-] (.*?)(?=\n|$)/g, '$1<li>$2</li>');
  text = text.replace(/(<li>.*<\/li>)/gs, '<ul>$1</ul>');
  // –ü—Ä–æ–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
  text = text.replace(/(^|\n)\d+\. (.*?)(?=\n|$)/g, '$1<ol><li>$2</li></ol>');
  // –ü–µ—Ä–µ–≤–æ–¥—ã —Å—Ç—Ä–æ–∫
  text = text.replace(/\n{2,}/g, '<br><br>');
  text = text.replace(/\n/g, '<br>');
  return text;
}

function escapeHtml(str) {
  return str.replace(/[&<>]/g, tag => ({'&':'&amp;','<':'&lt;','>':'&gt;'}[tag]));
}

function formatThinkingAndAnswer(think, answer) {
  let html = '';
  if (think) {
    html += `<div class="thinking-text">${simpleMarkdown(think)}</div>`;
  }
  if (answer) {
    html += simpleMarkdown(answer);
  }
  return html;
}

function addCopyButtonsToCodeBlocks(container) {
  const codeBlocks = container.querySelectorAll('.md-code-outer');
  codeBlocks.forEach(block => {
    if (block.querySelector('.copy-code-btn')) return; // –ù–µ –¥–æ–±–∞–≤–ª—è—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω–æ
    const btn = document.createElement('button');
    btn.textContent = 'üìã';
    btn.className = 'copy-code-btn';
    btn.title = '–°–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥';
    btn.style.position = 'absolute';
    btn.style.top = '4px';
    btn.style.right = '4px';
    btn.style.zIndex = 2;
    btn.onclick = () => {
      const code = block.querySelector('code').innerText;
      navigator.clipboard.writeText(code);
      btn.textContent = '‚úÖ';
      setTimeout(() => { btn.textContent = 'üìã'; }, 1000);
    };
    block.style.position = 'relative';
    block.appendChild(btn);
  });
}

function addMessage(text, sender, isMarkdown = false, saveToChat = true) {
  const div = document.createElement('div');
  div.className = 'message ' + sender;
  div.style.fontSize = chatFontSize + 'px';
  if (isMarkdown && markdownHighlightEnabled) {
    let html = simpleMarkdown(text);
    div.innerHTML = html;
  } else if (isMarkdown) {
    div.innerHTML = escapeHtml(text).replace(/\n/g, '<br>');
  } else {
    div.textContent = text;
  }
  chat.appendChild(div);
  chat.scrollTop = chat.scrollHeight;
  
  // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —Ç–µ–∫—É—â–∏–π —á–∞—Ç
  if (saveToChat && chats.length > 0) {
    chats[currentChatIndex].messages.push({
      text: text,
      sender: sender,
      isMarkdown: isMarkdown,
      timestamp: Date.now()
    });
    saveChats();
  }
}

async function loadModels() {
  try {
    const models = await window.electronAPI.getModels();
    modelSelect.innerHTML = '';
    models.forEach(m => {
      const opt = document.createElement('option');
      opt.value = m;
      opt.textContent = m;
      modelSelect.appendChild(opt);
    });
    
    // –ï—Å–ª–∏ –Ω–µ—Ç –º–æ–¥–µ–ª–µ–π, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ —Ç–æ–º, —á—Ç–æ Ollama –Ω–µ –∑–∞–ø—É—â–µ–Ω
    if (models.length === 0) {
      addMessage('‚ö†Ô∏è Ollama –Ω–µ –∑–∞–ø—É—â–µ–Ω –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ Ollama —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ –∑–∞–ø—É—â–µ–Ω –∫–æ–º–∞–Ω–¥–æ–π "ollama serve"', 'ai', false);
    }
  } catch (error) {
    addMessage('‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama. –£–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ Ollama –∑–∞–ø—É—â–µ–Ω –∫–æ–º–∞–Ω–¥–æ–π "ollama serve"', 'ai', false);
  }
}

form.addEventListener('submit', async (e) => {
  e.preventDefault();
  const userMsg = input.value.trim();
  if (!userMsg) return;
  addMessage(userMsg, 'user');
  input.value = '';
  
  // –ö–Ω–æ–ø–∫–∞ —Å—Ç–æ–ø
  const stopBtn = document.getElementById('stop-btn');
  stopBtn.style.display = '';
  let stopped = false;
  let controller = new AbortController();
  stopBtn.onclick = () => {
    stopped = true;
    controller.abort();
    window.stopped = true;
    window.electronAPI.abortRequest();
    stopBtn.style.display = 'none';
  };

  const model = modelSelect.value;
  
  // –°–æ–∑–¥–∞—ë–º —Å–æ–æ–±—â–µ–Ω–∏–µ AI –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞
  const aiMessageDiv = document.createElement('div');
  aiMessageDiv.className = 'message ai';
  aiMessageDiv.style.fontSize = chatFontSize + 'px';
  chat.appendChild(aiMessageDiv);
  chat.scrollTop = chat.scrollHeight;
  
  // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞
  window.currentAiMessageDiv = aiMessageDiv;
  window.fullMessage = '';
  window.think = '';
  window.answer = '';
  window.stopped = stopped;
  
  // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞
  setupStreamHandler();
  
  try {
    const result = await window.electronAPI.sendMessage(userMsg, model, controller.signal);
    
    // –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
    if (!stopped) {
      if (typeof result === 'object' && result !== null) {
        if (result.think) {
          window.think = result.think;
          window.answer = result.answer;
        } else {
          window.answer = result.answer || result;
        }
      } else {
        window.answer = result;
      }
      
      // –§–∏–Ω–∞–ª—å–Ω–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
      if (markdownHighlightEnabled) {
        aiMessageDiv.innerHTML = formatThinkingAndAnswer(window.think, window.answer);
        addCopyButtonsToCodeBlocks(aiMessageDiv);
      } else {
        let displayText = '';
        if (window.think) {
          displayText += '**–ú—ã—Å–ª–∏:**\n' + window.think + '\n\n';
        }
        displayText += window.answer;
        aiMessageDiv.textContent = displayText;
      }
      
      // –°–æ—Ö—Ä–∞–Ω—è–µ–º AI —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —á–∞—Ç
      if (chats.length > 0) {
        let aiMessageText;
        if (markdownHighlightEnabled) {
          // –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ HTML-—Ä–∞–∑–º–µ—Ç–∫–∏
          aiMessageText = window.answer;
          if (window.think) {
            aiMessageText = `<think>${window.think}</think>${aiMessageText}`;
          }
        } else {
          aiMessageText = window.answer;
          if (window.think) {
            aiMessageText = `**–ú—ã—Å–ª–∏:**\n${window.think}\n\n${aiMessageText}`;
          }
        }
        
        chats[currentChatIndex].messages.push({
          text: aiMessageText,
          sender: 'ai',
          isMarkdown: markdownHighlightEnabled,
          timestamp: Date.now()
        });
        saveChats();
      }
    }
  } catch (err) {
    if (!stopped) {
      if (err.message === 'Request aborted') {
        aiMessageDiv.textContent = '–û—Ç–≤–µ—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.';
      } else {
        aiMessageDiv.textContent = '–û—à–∏–±–∫–∞: ' + err.message;
      }
    }
  }
  
  // –û—á–∏—â–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
  window.currentAiMessageDiv = null;
  window.stopped = false;
  stopBtn.style.display = 'none';
});

const i18n = {
  en: {
    settings_title: 'Settings',
    settings_markdown: 'Markdown highlighting',
    settings_fontsize: 'Font size:',
    settings_lang: 'Language:',
    model_label: 'Model:',
    input_placeholder: 'Type a message...',
    send_btn: 'Send',
    stop_btn: 'Stop',
    about_title: 'About',
    about_text: 'Fllama 1.0 <br>Desktop chat on Electron for Ollama. <br>Version 1.0.0 <br> Author: ArduRadioKot(Alexander)',
    about_github: 'Project GitHub',
    about_ok: 'OK',
    download_model_btn: 'Download',
    models_title: 'Models',
    models_no_models: 'No models installed.',
    models_refresh: 'Refresh',
    models_download: 'Download',
    models_list: 'Installed models',
    models_available: 'Popular models for install',
    models_all_note: 'See all models on',
  },
  ru: {
    settings_title: '–ù–∞—Å—Ç—Ä–æ–π–∫–∏',
    settings_markdown: '–ü–æ–¥—Å–≤–µ—Ç–∫–∞ Markdown',
    settings_fontsize: '–†–∞–∑–º–µ—Ä —à—Ä–∏—Ñ—Ç–∞:',
    settings_lang: '–Ø–∑—ã–∫:',
    model_label: '–ú–æ–¥–µ–ª—å:',
    input_placeholder: '–í–≤–µ–¥–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...',
    send_btn: '–û—Ç–ø—Ä–∞–≤–∏—Ç—å',
    stop_btn: '–°—Ç–æ–ø',
    about_title: '–û –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏',
    about_text: 'Fllama 1.0 <br>–î–µ—Å–∫—Ç–æ–ø-—á–∞—Ç –Ω–∞ Electron –¥–ª—è Ollama. <br>–í–µ—Ä—Å–∏—è 1.0.0 <br> –ê–≤—Ç–æ—Ä: ArduRadioKot(–ê–ª–µ–∫—Å–∞–Ω–¥—Ä)',
    about_github: 'GitHub –ø—Ä–æ–µ–∫—Ç–∞',
    about_ok: '–û–ö',
    download_model_btn: '–°–∫–∞—á–∞—Ç—å',
    models_title: '–ú–æ–¥–µ–ª–∏',
    models_no_models: '–ù–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.',
    models_refresh: '–û–±–Ω–æ–≤–∏—Ç—å',
    models_download: '–°–∫–∞—á–∞—Ç—å',
    models_list: '–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏',
    models_available: '–ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏',
    models_all_note: '–í—Å–µ –º–æ–¥–µ–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã –Ω–∞',
  }
};
let currentLang = 'en';

function applyI18n() {
  document.querySelectorAll('[data-i18n]').forEach(el => {
    const key = el.getAttribute('data-i18n');
    if (i18n[currentLang][key]) el.innerHTML = i18n[currentLang][key];
  });
  document.querySelectorAll('[data-i18n-placeholder]').forEach(el => {
    const key = el.getAttribute('data-i18n-placeholder');
    if (i18n[currentLang][key]) el.setAttribute('placeholder', i18n[currentLang][key]);
  });
}

const POPULAR_MODELS = [
  'tinyllama', 'llama3.2', 'llama3.1', 'qwen3', 'gemma3', 'deepseek-r1', 'deepseek-coder', 'phi3', 'qwen2.5-coder'
];

const MODEL_INFOS = {
  'tinyllama': {
    en: {title: 'TinyLlama', desc: 'The TinyLlama project is an open endeavor to train a compact 1.1B Llama model on 3 trillion tokens.',
      readme: 'TinyLlama is a compact model with only 1.1B parameters. This compactness allows it to cater to a multitude of applications demanding a restricted computation and memory footprint.',
      variants: [
        {name: 'tinyllama:1.1b', size: '638MB', type: 'base'}
      ]},
    ru: {title: 'TinyLlama', desc: 'TinyLlama ‚Äî –æ—Ç–∫—Ä—ã—Ç—ã–π –ø—Ä–æ–µ–∫—Ç –ø–æ –æ–±—É—á–µ–Ω–∏—é –∫–æ–º–ø–∞–∫—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏ Llama —Å 1,1 –º–ª—Ä–¥ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –Ω–∞ 3 —Ç—Ä–∏–ª–ª–∏–æ–Ω–∞—Ö —Ç–æ–∫–µ–Ω–æ–≤.',
      readme: 'TinyLlama ‚Äî –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è –º–æ–¥–µ–ª—å –≤—Å–µ–≥–æ —Å 1,1 –º–ª—Ä–¥ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤. –ë–ª–∞–≥–æ–¥–∞—Ä—è —Å–≤–æ–µ–π –∫–æ–º–ø–∞–∫—Ç–Ω–æ—Å—Ç–∏ –æ–Ω–∞ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞ –∑–∞–¥–∞—á, –≥–¥–µ –≤–∞–∂–Ω—ã –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–µ –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã –∏ –ø–∞–º—è—Ç—å.',
      variants: [
        {name: 'tinyllama:1.1b', size: '638MB', type: 'base'}
      ]}
  },
  'llama3.2': {
    en: {title: 'Llama 3.2', desc: 'Meta`s Llama 3.2 goes small with 1B and 3B models.',
      readme: 'The Meta Llama 3.2 collection of multilingual large language models (LLMs) is a collection of pretrained and instruction-tuned generative models in 1B and 3B sizes (text in/text out). The Llama 3.2 instruction-tuned text only models are optimized for multilingual dialogue use cases, including agentic retrieval and summarization tasks. They outperform many of the available open source and closed chat models on common industry benchmarks.',
      variants: [
        {name: 'llama3.2:1b', size: '1.3GB', type: 'base'},
        {name: 'llama3.2:3b', size: '2GB', type: 'base'}
      ]},
    ru: {title: 'Llama 3.2', desc: 'Llama 3.2 –æ—Ç Meta ‚Äî –∫–æ–º–ø–∞–∫—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ –Ω–∞ 1B –∏ 3B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.',
      readme: '–ö–æ–ª–ª–µ–∫—Ü–∏—è Meta Llama 3.2 ‚Äî —ç—Ç–æ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–µ –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ (LLM), –≤–∫–ª—é—á–∞—é—â–∏–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –∏ –¥–æ–æ–±—É—á–µ–Ω–Ω—ã–µ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Ä–∞–∑–º–µ—Ä–æ–º 1B –∏ 3B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤. –ú–æ–¥–µ–ª–∏, –¥–æ–æ–±—É—á–µ–Ω–Ω—ã–µ –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤, –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–≥–æ –æ–±—â–µ–Ω–∏—è, –ø–æ–∏—Å–∫–∞ –∏ —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏. –û–Ω–∏ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥—è—Ç –º–Ω–æ–≥–∏–µ –æ—Ç–∫—Ä—ã—Ç—ã–µ –∏ –∑–∞–∫—Ä—ã—Ç—ã–µ –∞–Ω–∞–ª–æ–≥–∏ –ø–æ –æ—Ç—Ä–∞—Å–ª–µ–≤—ã–º –±–µ–Ω—á–º–∞—Ä–∫–∞–º.',
      variants: [
        {name: 'llama3.2:1b', size: '1.3GB', type: 'base'},
        {name: 'llama3.2:3b', size: '2GB', type: 'base'}
      ]}
  },
  'llama3.1': {
    en: {title: 'Llama 3.1', desc: 'Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and 405B parameter sizes.',
      readme: 'Llama 3.1 405B is the first openly available model that rivals the top AI models when it comes to state-of-the-art capabilities in general knowledge, steerability, math, tool use, and multilingual translation.',
      variants: [
        {name: 'llama3.1:8b', size: '4.9GB', type: 'base'},
      ]},
    ru: {title: 'Llama 3.1', desc: 'Llama 3.1 ‚Äî –Ω–æ–≤–∞—è –ø–µ—Ä–µ–¥–æ–≤–∞—è –º–æ–¥–µ–ª—å –æ—Ç Meta, –¥–æ—Å—Ç—É–ø–Ω–∞—è –≤ –≤–µ—Ä—Å–∏—è—Ö –Ω–∞ 8B, 70B –∏ 405B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.',
      readme: 'Llama 3.1 405B ‚Äî –ø–µ—Ä–≤–∞—è –æ—Ç–∫—Ä—ã—Ç–∞—è –º–æ–¥–µ–ª—å, —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–∞—è —Å –ª—É—á—à–∏–º–∏ –ò–ò –ø–æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è–º –≤ –æ–±–ª–∞—Å—Ç–∏ –∑–Ω–∞–Ω–∏–π, —É–ø—Ä–∞–≤–ª—è–µ–º–æ—Å—Ç–∏, –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏, —Ä–∞–±–æ—Ç—ã —Å –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏ –∏ –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞.',
      variants: [
        {name: 'llama3.1:8b', size: '4.9GB', type: 'base'},
      ]}
  },
  'qwen3': {
    en: {title: 'Qwen3', desc: 'Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.',
      readme: 'Qwen 3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. The flagship model, Qwen3-235B-A22B, achieves competitive results in benchmark evaluations of coding, math, general capabilities, etc., when compared to other top-tier models such as DeepSeek-R1, o1, o3-mini, Grok-3, and Gemini-2.5-Pro. Additionally, the small MoE model, Qwen3-30B-A3B, outcompetes QwQ-32B with 10 times of activated parameters, and even a tiny model like Qwen3-4B can rival the performance of Qwen2.5-72B-Instruct.',
      variants: [
        {name: 'qwen3:0.6b', size: '523MB', type: 'base'},
        {name: 'qwen3:1.7b', size: '1.4GB', type: 'base'},
        {name: 'qwen3:4b', size: '2.6GB', type: 'base'},
        {name: 'qwen3:14b', size: '5.2GB', type: 'base'}
      ]},
    ru: {title: 'Qwen3', desc: 'Qwen3 ‚Äî –ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø–æ–∫–æ–ª–µ–Ω–∏–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å–µ—Ä–∏–∏ Qwen, –≤–∫–ª—é—á–∞—é—â–µ–µ –ø–ª–æ—Ç–Ω—ã–µ –∏ Mixture-of-Experts (MoE) –≤–∞—Ä–∏–∞–Ω—Ç—ã.',
      readme: 'Qwen 3 ‚Äî —ç—Ç–æ –Ω–æ–≤–æ–µ –ø–æ–∫–æ–ª–µ–Ω–∏–µ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π Qwen, –≤–∫–ª—é—á–∞—é—â–µ–µ –∫–∞–∫ –ø–ª–æ—Ç–Ω—ã–µ, —Ç–∞–∫ –∏ MoE-–º–æ–¥–µ–ª–∏. –§–ª–∞–≥–º–∞–Ω Qwen3-235B-A22B –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –∑–∞–¥–∞—á–∞—Ö –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è, –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ –∏ –æ–±—â–µ–≥–æ –ò–ò, —Å–æ–ø–µ—Ä–Ω–∏—á–∞—è —Å DeepSeek-R1, o1, o3-mini, Grok-3 –∏ Gemini-2.5-Pro. –î–∞–∂–µ –∫–æ–º–ø–∞–∫—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Å–µ—Ä–∏–∏ Qwen3 –º–æ–≥—É—Ç –∫–æ–Ω–∫—É—Ä–∏—Ä–æ–≤–∞—Ç—å —Å –±–æ–ª–µ–µ –∫—Ä—É–ø–Ω—ã–º–∏ –∞–Ω–∞–ª–æ–≥–∞–º–∏.',
      variants: [
        {name: 'qwen3:0.6b', size: '523MB', type: 'base'},
        {name: 'qwen3:1.7b', size: '1.4GB', type: 'base'},
        {name: 'qwen3:4b', size: '2.6GB', type: 'base'},
        {name: 'qwen3:14b', size: '5.2GB', type: 'base'}
      ]}
  },
  'gemma3': {
    en: {title: 'Gemma 3', desc: 'The current, most capable model that runs on a single GPU.',
      readme: 'Gemma is a lightweight, family of models from Google built on Gemini technology. The Gemma 3 models are multimodal‚Äîprocessing text and images‚Äîand feature a 128K context window with support for over 140 languages. Available in 1B, 4B, 12B, and 27B parameter sizes, they excel in tasks like question answering, summarization, and reasoning, while their compact design allows deployment on resource-limited devices.',
      variants: [
        {name: 'gemma3:1b', size: '815MB', type: 'base'},
        {name: 'gemma3:4b', size: '3.3GB', type: 'base'},
        {name: 'gemma3:12b', size: '8.1GB', type: 'base'}
      ]},
    ru: {title: 'Gemma 3', desc: 'Gemma 3 ‚Äî —Å–∞–º–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å, —Ä–∞–±–æ—Ç–∞—é—â–∞—è –Ω–∞ –æ–¥–Ω–æ–π –≤–∏–¥–µ–æ–∫–∞—Ä—Ç–µ.',
      readme: 'Gemma ‚Äî —Å–µ–º–µ–π—Å—Ç–≤–æ –ª–µ–≥–∫–æ–≤–µ—Å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –æ—Ç Google –Ω–∞ –±–∞–∑–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π Gemini. –ú–æ–¥–µ–ª–∏ Gemma 3 —è–≤–ª—è—é—Ç—Å—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã–º–∏ (—Ä–∞–±–æ—Ç–∞—é—Ç —Å —Ç–µ–∫—Å—Ç–æ–º –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏), –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–æ 128–ö —Ç–æ–∫–µ–Ω–æ–≤ –∏ –±–æ–ª–µ–µ 140 —è–∑—ã–∫–æ–≤. –î–æ—Å—Ç—É–ø–Ω—ã –≤–∞—Ä–∏–∞–Ω—Ç—ã –Ω–∞ 1B, 4B, 12B –∏ 27B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤. –û—Ç–ª–∏—á–∞—é—Ç—Å—è –≤—ã—Å–æ–∫–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é –ø—Ä–∏ –∫–æ–º–ø–∞–∫—Ç–Ω—ã—Ö —Ä–∞–∑–º–µ—Ä–∞—Ö, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–ø—É—Å–∫–∞—Ç—å –∏—Ö –¥–∞–∂–µ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞—Ö —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º–∏ —Ä–µ—Å—É—Ä—Å–∞–º–∏.',
      variants: [
        {name: 'gemma3:1b', size: '815MB', type: 'base'},
        {name: 'gemma3:4b', size: '3.3GB', type: 'base'},
        {name: 'gemma3:12b', size: '8.1GB', type: 'base'}
      ]}
  },
  'deepseek-r1': {
    en: {title: 'DeepSeek R1', desc: 'DeepSeek-R1 is a family of open reasoning models with performance approaching that of leading models, such as O3 and Gemini 2.5 Pro.',
      readme: 'DeepSeek-R1 has received a minor version upgrade to DeepSeek-R1-0528 for the 8 billion parameter distilled model and the full 671 billion parameter model. In this update, DeepSeek R1 has significantly improved its reasoning and inference capabilities. The model has demonstrated outstanding performance across various benchmark evaluations, including mathematics, programming, and general logic. Its overall performance is now approaching that of leading models, such as O3 and Gemini 2.5 Pro.',
      variants: [
        {name: 'deepseek-r1:1.5b', size: '1.1GB', type: 'base'},
        {name: 'deepseek-r1:7b', size: '4.7GB', type: 'base'},
        {name: 'deepseek-r1:8b', size: '5.2GB', type: 'base'},
        {name: 'deepseek-r1:14b', size: '9.0GB', type: 'base'},
      ]},
    ru: {title: 'DeepSeek R1', desc: 'DeepSeek-R1 ‚Äî —Å–µ–º–µ–π—Å—Ç–≤–æ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π —Å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å—é, –ø—Ä–∏–±–ª–∏–∂–∞—é—â–µ–π—Å—è –∫ –ª–∏–¥–µ—Ä–∞–º —Ä—ã–Ω–∫–∞.',
      readme: 'DeepSeek-R1 –Ω–µ–¥–∞–≤–Ω–æ –æ–±–Ω–æ–≤–∏–ª–∞—Å—å –¥–æ –≤–µ—Ä—Å–∏–∏ DeepSeek-R1-0528 –¥–ª—è –¥–∏—Å—Ç–∏–ª–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ 8B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –ø–æ–ª–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ 671B. –í —ç—Ç–æ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–µ–Ω—ã —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∫ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—é –∏ –≤—ã–≤–æ–¥—É. –ú–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –æ—Ç–ª–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö –ø–æ –º–∞—Ç–µ–º–∞—Ç–∏–∫–µ, –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é –∏ –ª–æ–≥–∏–∫–µ, –ø—Ä–∏–±–ª–∏–∂–∞—è—Å—å –∫ —Ç–∞–∫–∏–º –ª–∏–¥–µ—Ä–∞–º, –∫–∞–∫ O3 –∏ Gemini 2.5 Pro.',
      variants: [
        {name: 'deepseek-r1:1.5b', size: '1.1GB', type: 'base'},
        {name: 'deepseek-r1:7b', size: '4.7GB', type: 'base'},
        {name: 'deepseek-r1:8b', size: '5.2GB', type: 'base'},
        {name: 'deepseek-r1:14b', size: '9.0GB', type: 'base'},
      ]}
  },
  'deepseek-coder': {
    en: {title: 'DeepSeek Coder', desc: 'DeepSeek Coder is a capable coding model trained on two trillion code and natural language tokens.',
      readme: 'DeepSeek Coder is trained from scratch on both 87% code and 13% natural language in English and Chinese. Each of the models are pre-trained on 2 trillion tokens.',
      variants: [
        {name: 'deepseek-coder:1.3b', size: '776MB', type: 'base'},
        {name: 'deepseek-coder:6.7b', size: '3.8GB', type: 'base'},
      ]},
    ru: {title: 'DeepSeek Coder', desc: 'DeepSeek Coder ‚Äî –º–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è, –æ–±—É—á–µ–Ω–Ω–∞—è –Ω–∞ –¥–≤—É—Ö —Ç—Ä–∏–ª–ª–∏–æ–Ω–∞—Ö —Ç–æ–∫–µ–Ω–æ–≤ –∫–æ–¥–∞ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞.',
      readme: 'DeepSeek Coder –æ–±—É—á–µ–Ω–∞ —Å –Ω—É–ª—è –Ω–∞ 87% –∫–æ–¥–∞ –∏ 13% —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –∏ –∫–∏—Ç–∞–π—Å–∫–æ–º —è–∑—ã–∫–∞—Ö. –ö–∞–∂–¥–∞—è –∏–∑ –º–æ–¥–µ–ª–µ–π –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –æ–±—É—á–µ–Ω–∞ –Ω–∞ 2 —Ç—Ä–∏–ª–ª–∏–æ–Ω–∞—Ö —Ç–æ–∫–µ–Ω–æ–≤.',
      variants: [
        {name: 'deepseek-coder:1.3b', size: '776MB', type: 'base'},
        {name: 'deepseek-coder:6.7b', size: '3.8GB', type: 'base'},
      ]}
  },
  'phi3': {
    en: {title: 'Phi-3', desc: 'Phi-3 is a family of lightweight 3B (Mini) and 14B (Medium) state-of-the-art open models by Microsoft.',
      readme: 'Phi-3 is a family of open AI models developed by Microsoft.',
      variants: [
        {name: 'phi3:mini', size: '2.2GB', type: 'base'},
        {name: 'phi3:medium', size: '7.9GB', type: 'base'}
      ]},
    ru: {title: 'Phi-3', desc: 'Phi-3 ‚Äî —Å–µ–º–µ–π—Å—Ç–≤–æ –ª–µ–≥–∫–æ–≤–µ—Å–Ω—ã—Ö –æ—Ç–∫—Ä—ã—Ç—ã—Ö –º–æ–¥–µ–ª–µ–π –æ—Ç Microsoft –Ω–∞ 3B (Mini) –∏ 14B (Medium) –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.',
      readme: 'Phi-3 ‚Äî —Å–µ–º–µ–π—Å—Ç–≤–æ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –ò–ò-–º–æ–¥–µ–ª–µ–π, —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö Microsoft.',
      variants: [
        {name: 'phi3:mini', size: '2.2GB', type: 'base'},
        {name: 'phi3:medium', size: '7.9GB', type: 'base'}
      ]}
  },
  'qwen2.5-coder': {
    en: {title: 'Qwen2.5 Coder', desc: 'The latest series of Code-Specific Qwen models, with significant improvements in code generation, code reasoning, and code fixing.',
      readme: 'Qwen 2.5 Coder series of models are now updated in 6 sizes: 0.5B, 1.5B, 3B, 7B, 14B and 32B. There are significant improvements in code generation, code reasoning and code fixing. The 32B model has competitive performance with OpenAI‚Äôs GPT-4o.',
      variants: [
        {name: 'qwen2.5-coder:0.5b', size: '398MB', type: 'base'},
        {name: 'qwen2.5-coder:1.5b', size: '986MB', type: 'base'},
        {name: 'qwen2.5-coder:3b', size: '1.9GB', type: 'base'},
        {name: 'qwen2.5-coder:7b', size: '4.7GB', type: 'base'},
        {name: 'qwen2.5-coder:14b', size: '9GB', type: 'base'},
      ]},
    ru: {title: 'Qwen2.5 Coder', desc: 'Qwen2.5 Coder ‚Äî –Ω–æ–≤–µ–π—à–∞—è —Å–µ—Ä–∏—è –º–æ–¥–µ–ª–µ–π Qwen, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–æ–¥–∞, —Å –∑–∞–º–µ—Ç–Ω—ã–º–∏ —É–ª—É—á—à–µ–Ω–∏—è–º–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–¥–∞.',
      readme: '–°–µ—Ä–∏—è –º–æ–¥–µ–ª–µ–π Qwen 2.5 Coder —Ç–µ–ø–µ—Ä—å –¥–æ—Å—Ç—É–ø–Ω–∞ –≤ 6 —Ä–∞–∑–º–µ—Ä–∞—Ö: 0.5B, 1.5B, 3B, 7B, 14B –∏ 32B. –°—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ —É–ª—É—á—à–µ–Ω—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏—è, —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–¥–∞. –ú–æ–¥–µ–ª—å –Ω–∞ 32B –ø–æ –∫–∞—á–µ—Å—Ç–≤—É —Å–æ–ø–æ—Å—Ç–∞–≤–∏–º–∞ —Å OpenAI GPT-4o.',
      variants: [
        {name: 'qwen2.5-coder:0.5b', size: '398MB', type: 'base'},
        {name: 'qwen2.5-coder:1.5b', size: '986MB', type: 'base'},
        {name: 'qwen2.5-coder:3b', size: '1.9GB', type: 'base'},
        {name: 'qwen2.5-coder:7b', size: '4.7GB', type: 'base'},
        {name: 'qwen2.5-coder:14b', size: '9GB', type: 'base'},
      ]}
  }
};

window.addEventListener('DOMContentLoaded', () => {
  loadModels();
  applyI18n();
  loadChats(); 

  // –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ —á–∞—Ç–∞
  document.getElementById('new-chat-btn').addEventListener('click', () => {
    createNewChat();
  });

  // –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–∑–¥–∞–Ω–∏—è –Ω–æ–≤–æ–≥–æ —á–∞—Ç–∞ —á–µ—Ä–µ–∑ –≤–∫–ª–∞–¥–∫–∏
  document.getElementById('new-tab-btn').addEventListener('click', () => {
    createNewChat();
  });

  // –ú–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–∫
  const modal = document.getElementById('modal-settings');
  const closeBtn = document.getElementById('close-settings');
  document.getElementById('open-settings-btn').addEventListener('click', () => {
    modal.style.display = 'flex';
  });
  closeBtn.addEventListener('click', () => {
    modal.style.display = 'none';
  });
  modal.addEventListener('click', (e) => {
    if (e.target === modal) modal.style.display = 'none';
  });

  // –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –∫–Ω–æ–ø–∫–∏ OK –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö
  document.getElementById('close-settings-btn').addEventListener('click', () => {
    modal.style.display = 'none';
  });

  // –ú–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
  const infoModal = document.getElementById('modal-info');
  const closeInfoBtn = document.getElementById('close-info');
  document.getElementById('open-info-btn').addEventListener('click', () => {
    infoModal.style.display = 'flex';
  });
  closeInfoBtn.addEventListener('click', () => {
    infoModal.style.display = 'none';
  });
  infoModal.addEventListener('click', (e) => {
    if (e.target === infoModal) infoModal.style.display = 'none';
  });

  // –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è GitHub –≤ —Å–∏—Å—Ç–µ–º–Ω–æ–º –±—Ä–∞—É–∑–µ—Ä–µ
  document.querySelector('a[href="https://github.com/ArduRadioKot/Fllama"]').addEventListener('click', (e) => {
    e.preventDefault();
    window.electronAPI.openExternal('https://github.com/ArduRadioKot/Fllama');
  });

  // –ù–∞—Å—Ç—Ä–æ–π–∫–∏: markdown highlight
  const toggleMarkdown = document.getElementById('toggle-markdown');
  const toggleMarkdownCheckbox = document.getElementById('toggle-markdown-checkbox');
  toggleMarkdown.checked = markdownHighlightEnabled;
  toggleMarkdownCheckbox.classList.toggle('checked', markdownHighlightEnabled);
  
  toggleMarkdownCheckbox.addEventListener('click', () => {
    toggleMarkdown.checked = !toggleMarkdown.checked;
    markdownHighlightEnabled = toggleMarkdown.checked;
    toggleMarkdownCheckbox.classList.toggle('checked', markdownHighlightEnabled);
  });
  
  toggleMarkdown.addEventListener('change', () => {
    markdownHighlightEnabled = toggleMarkdown.checked;
    toggleMarkdownCheckbox.classList.toggle('checked', markdownHighlightEnabled);
  });

  // –ù–∞—Å—Ç—Ä–æ–π–∫–∏: font size
  const fontSizeSelect = document.getElementById('font-size-select');
  fontSizeSelect.value = chatFontSize;
  fontSizeSelect.addEventListener('change', () => {
    chatFontSize = parseInt(fontSizeSelect.value, 10);
    document.querySelectorAll('.message').forEach(div => {
      div.style.fontSize = chatFontSize + 'px';
    });
  });

  // –ù–∞—Å—Ç—Ä–æ–π–∫–∏: language
  const langSelect = document.getElementById('lang-select');
  langSelect.value = currentLang;
  langSelect.addEventListener('change', () => {
    currentLang = langSelect.value;
    applyI18n();
    document.getElementById('download-model-modal-btn').querySelector('span').textContent = i18n[currentLang].models_download;
    loadModelsList();
    renderPopularModels();
  });

  // –ú–æ–¥–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ –º–æ–¥–µ–ª–µ–π
  const modelsModal = document.getElementById('modal-models');
  const openModelsBtn = document.getElementById('open-models-btn');
  const closeModelsBtn = document.getElementById('close-models');
  const modelsList = document.getElementById('models-list');
  const refreshModelsBtn = document.getElementById('refresh-models-btn');
  const downloadModelInput = document.getElementById('download-model-input');
  const downloadModelModalBtn = document.getElementById('download-model-modal-btn');
  const modelsAvailableList = document.getElementById('models-available-list');

  async function loadModelsList() {
    modelsList.innerHTML = (currentLang === 'ru' ? '–ó–∞–≥—Ä—É–∑–∫–∞...' : 'Loading...');
    const models = await window.electronAPI.getModels();
    if (!models || !models.length) {
      modelsList.innerHTML = currentLang === 'ru' ? '–ù–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.' : 'No models installed.';
      return;
    }
    modelsList.innerHTML = models.map(m => `
      <div class="models-list-item">
        <span class="model-icon"></span>${m}
        <button class="delete-model-btn" title="${currentLang === 'ru' ? '–£–¥–∞–ª–∏—Ç—å –º–æ–¥–µ–ª—å' : 'Delete model'}" data-model="${m}">‚úñ</button>
      </div>
    `).join('');
    // –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —É–¥–∞–ª–µ–Ω–∏—è
    modelsList.querySelectorAll('.delete-model-btn').forEach(btn => {
      btn.onclick = async (e) => {
        const model = btn.getAttribute('data-model');
        btn.disabled = true;
        btn.textContent = '...';
        try {
          const result = await window.electronAPI.deleteModel(model);
          if (result && result.success) {
            loadModelsList();
          } else {
            alert((result && result.error) || (currentLang === 'ru' ? '–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è.' : 'Delete error.'));
            btn.disabled = false;
            btn.textContent = '‚úñ';
          }
        } catch (e) {
          alert(currentLang === 'ru' ? '–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è.' : 'Delete error.');
          btn.disabled = false;
          btn.textContent = '‚úñ';
        }
      };
    });
  }

  function renderPopularModels() {
    modelsAvailableList.innerHTML = POPULAR_MODELS.map(m => `<span class="models-available-item" title="${m}">${m}</span>`).join('');
    modelsAvailableList.querySelectorAll('.models-available-item').forEach(el => {
      el.onclick = () => {
        const model = el.textContent;
        let info = MODEL_INFOS[model];
        if (!info && model.includes(':')) info = MODEL_INFOS[model.split(':')[0]];
        // –û—á–∏—â–∞–µ–º –≤—Å–µ –ø–æ–ª—è
        document.getElementById('model-info-title').textContent = '';
        document.getElementById('model-info-desc').textContent = '';
        document.getElementById('model-info-readme').textContent = '';
        document.getElementById('model-info-variants').innerHTML = '';
        // –ó–∞–ø–æ–ª–Ω—è–µ–º
        const title = info ? info[currentLang].title : model;
        const desc = info ? info[currentLang].desc : (currentLang === 'ru' ? '–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è.' : 'No info.');
        const readme = info ? info[currentLang].readme : '';
        const variants = info ? (info[currentLang].variants || []) : [];
        document.getElementById('model-info-title').textContent = title;
        document.getElementById('model-info-desc').textContent = desc;
        document.getElementById('model-info-readme').textContent = readme;
        if (variants.length) {
          let table = '<table id="model-info-variants-table"><tr><th>Name</th><th>Size</th><th>Type</th></tr>';
          for (const v of variants) {
            table += `<tr><td>${v.name}</td><td>${v.size}</td><td>${v.type}</td></tr>`;
          }
          table += '</table>';
          document.getElementById('model-info-variants').innerHTML = table;
        }
        document.getElementById('modal-model-info').style.display = 'flex';
      };
    });
  }

  openModelsBtn.addEventListener('click', () => {
    modelsModal.style.display = 'flex';
    loadModelsList();
    renderPopularModels();
  });
  closeModelsBtn.addEventListener('click', () => {
    modelsModal.style.display = 'none';
  });
  modelsModal.addEventListener('click', (e) => {
    if (e.target === modelsModal) modelsModal.style.display = 'none';
  });
  refreshModelsBtn.addEventListener('click', loadModelsList);
  downloadModelModalBtn.addEventListener('click', async () => {
    const model = downloadModelInput.value.trim();
    if (!model) return;
    downloadModelModalBtn.disabled = true;
    downloadModelModalBtn.textContent = currentLang === 'ru' ? '–°–∫–∞—á–∏–≤–∞–Ω–∏–µ...' : 'Downloading...';
    try {
      const result = await window.electronAPI.downloadModel(model);
      alert(result && result.success ? (currentLang === 'ru' ? '–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–∞!' : 'Model downloaded!') : (result && result.error ? result.error : (currentLang === 'ru' ? '–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è.' : 'Download error.')));
      loadModelsList();
    } catch (e) {
      alert(currentLang === 'ru' ? '–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è.' : 'Download error.');
    }
    downloadModelModalBtn.disabled = false;
    downloadModelModalBtn.textContent = currentLang === 'ru' ? '–°–∫–∞—á–∞—Ç—å' : 'Download';
  });

  document.getElementById('close-model-info').onclick = () => {
    document.getElementById('modal-model-info').style.display = 'none';
  };
  document.getElementById('modal-model-info').addEventListener('click', (e) => {
    if (e.target === document.getElementById('modal-model-info')) document.getElementById('modal-model-info').style.display = 'none';
  });
  
  // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞
  setupStreamHandler();
}); 